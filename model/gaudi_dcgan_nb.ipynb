{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17efa227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Deps\n",
    "import random\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "# Torch Deps\n",
    "import torch\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "# DCGAN\n",
    "import gaudi_dcgan as dcgan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec446409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed Model\n",
    "random.seed(151)\n",
    "torch.manual_seed(151)\n",
    "\n",
    "# Init Model Config w. Default DCGAN Values\n",
    "model_cfg = dcgan.ModelCheckpointConfig()\n",
    "train_cfg = dcgan.TrainingConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d1a986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root directory for dataset\n",
    "dataroot = \"/efs/images/sample\"\n",
    "\n",
    "# We can use an image folder dataset the way we have it setup.\n",
    "dataset = dset.ImageFolder(\n",
    "    root=dataroot,\n",
    "    transform=transforms.Compose(\n",
    "        [\n",
    "            transforms.CenterCrop(train_cfg.img_size * 2),\n",
    "            transforms.Resize(train_cfg.img_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(\n",
    "                (\n",
    "                    0.5,\n",
    "                    0.5,\n",
    "                    0.5,\n",
    "                ),\n",
    "                (\n",
    "                    0.5,\n",
    "                    0.5,\n",
    "                    0.5,\n",
    "                ),\n",
    "            ),\n",
    "        ]\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Create the dataloader\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=train_cfg.batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=(os.cpu_count() - 1),\n",
    ")\n",
    "\n",
    "# Plot some training images\n",
    "real_batch = next(iter(dataloader))\n",
    "plt.figure(figsize=(16, 16))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Training Images\")\n",
    "plt.imshow(\n",
    "    np.transpose(\n",
    "        vutils.make_grid(\n",
    "            real_batch[0].to(train_cfg.dev)[:16], padding=2, normalize=True\n",
    "        ).cpu(),\n",
    "        (1, 2, 0),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429ec787",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = dcgan.start_or_resume_training_run(\n",
    "    dataloader, train_cfg, model_cfg, num_epochs=16, start_epoch=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909e6db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.title(\"Generator and Discriminator Loss During Training\")\n",
    "plt.plot(result[\"losses\"][\"_G\"], label=\"G\")\n",
    "plt.plot(result[\"losses\"][\"_D\"], label=\"D\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ba590a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 8))\n",
    "plt.axis(\"off\")\n",
    "ims = [\n",
    "    [plt.imshow(np.transpose(i, (1, 2, 0)), animated=True)] for i in result[\"img_list\"]\n",
    "]\n",
    "\n",
    "ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)\n",
    "\n",
    "content = HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2b075e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab a batch of real images from the dataloader\n",
    "real_batch = next(iter(dataloader))\n",
    "\n",
    "# Plot the real images\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Real Images\")\n",
    "plt.imshow(\n",
    "    np.transpose(\n",
    "        vutils.make_grid(\n",
    "            real_batch[0].to(train_cfg.dev)[:64], padding=5, normalize=True\n",
    "        ).cpu(),\n",
    "        (1, 2, 0),\n",
    "    )\n",
    ")\n",
    "\n",
    "# Plot the fake images from the last epoch\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Fake Images\")\n",
    "plt.imshow(np.transpose(result['img_list'][-1], (1, 2, 0)))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
