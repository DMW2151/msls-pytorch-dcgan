{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b9efa71",
   "metadata": {},
   "source": [
    "# DCGAN - SageMaker Training\n",
    "\n",
    "This notebook is a wrapper around `gaudi_dcgan.py` and is provided for those who might prefer\n",
    "to train on Sagemaker using a GPU instance (or those who have the determination to run a NB server \n",
    "on-top of a DL1 instance). \n",
    "\n",
    "This notebook does **NOT** take full advantage of the Gaudi accelerators and I would direct you to \n",
    "`run_gaudi_dcgan.py` for the fully-migrated training experience.\n",
    "\n",
    "**NOTE:** On Sagemaker either the `conda_amazonei_pytorch_latest_p37` (on `notebook-al2-v1`) OR `conda_pytorch_p36` (on `notebook-al1-v1`) kernels will be satisfactory for this notebook.\n",
    "\n",
    "-----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a849e09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Deps\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Torch Deps\n",
    "import torch\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "# DCGAN\n",
    "import gaudi_dcgan as dcgan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f999b78",
   "metadata": {},
   "source": [
    "## Data Loading & Transformations \n",
    "--------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e6e22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Inputs\n",
    "SEED = 215\n",
    "DATAROOT = \"/efs/images/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec446409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed PyTorch\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# Init Model and Training Configs w. Default Values - See gaudi_dcgan.py for descriptions. For clarity,\n",
    "# objects below are initialized with their default values.\n",
    "model_cfg = dcgan.ModelCheckpointConfig(\n",
    "    batch_size=128,\n",
    "    img_size=64,\n",
    "    nc=3,\n",
    "    nz=100,\n",
    "    ngf=64,\n",
    "    ndf=64,\n",
    "    lr=0.0002,\n",
    "    beta1=0.5,\n",
    "    beta2=0.999,\n",
    ")\n",
    "\n",
    "train_cfg = dcgan.TrainingConfig(\n",
    "    model_name=\"msls_dcgan_ml_p3_8xlarge_001\", # Custom Model Name To Identify Gaudi vs GPU Trained!\n",
    "    model_dir=\"/efs/trained_model\",\n",
    "    save_frequency=1,\n",
    "    log_frequency=50,\n",
    "    gen_progress_frequency=250,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0cd131d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%% time\n",
    "\n",
    "# In general, the ImageFolder/Dataloader reads from the directory of images and applys a transformation\n",
    "# at runtime to generate our training images. See `Data and Transformations` section for details.\n",
    "dataset = dset.ImageFolder(\n",
    "    root=DATAROOT,\n",
    "    transform=transforms.Compose(\n",
    "        [\n",
    "            transforms.RandomAffine(degrees=0, translate=(0.3, 0.0)),\n",
    "            transforms.CenterCrop(train_cfg.img_size * 4),\n",
    "            transforms.Resize(train_cfg.img_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(\n",
    "                (\n",
    "                    0.5,\n",
    "                    0.5,\n",
    "                    0.5,\n",
    "                ),\n",
    "                (\n",
    "                    0.5,\n",
    "                    0.5,\n",
    "                    0.5,\n",
    "                ),\n",
    "            ),\n",
    "        ]\n",
    "    ),\n",
    ")\n",
    "\n",
    "# The Habana analog to Pytorch's DataLoader can be more efficient on Gaudi-Accelerated instances under\n",
    "# specific conditions. Here, we create the dataloader with *similar* params to those that would cause\n",
    "# the ht.DataLoader() to use acceleration. \n",
    "\n",
    "# NOTE: This step can be slow as the images are processed (esp. on a new EFS); anecdotally, around 8-10 \n",
    "# min to load 1MM images (~30GB total)\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    shuffle=False,\n",
    "    num_workers=8,\n",
    "    pin_memory=True,\n",
    "    timeout=0,\n",
    "    batch_size=train_cfg.batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86295448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that the dset.ImageFolder && data.DataLoader are correct and the training data look OK\n",
    "real_batch = next(iter(dataloader))\n",
    "plt.figure(figsize=(16, 16))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Training Images\")\n",
    "\n",
    "# Plot and Save Sample Training Images\n",
    "plt.imshow(\n",
    "    np.transpose(\n",
    "        vutils.make_grid(\n",
    "            real_batch[0].to(train_cfg.dev)[:16], padding=2, normalize=True\n",
    "        ).cpu(),\n",
    "        (1, 2, 0),\n",
    "    )\n",
    ")\n",
    "\n",
    "# Create Figures Directory if Not Yet Exists\n",
    "if not os.path.exists(f\"{model_cfg.model_dir}/{model_cfg.model_name}/figures\"):\n",
    "    os.makedirs(f\"{model_cfg.model_dir}/{model_cfg.model_name}/figures\")\n",
    "\n",
    "plt.savefig(f\"{model_cfg.model_dir}/{model_cfg.model_name}/figures/train_samples.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601238da",
   "metadata": {},
   "source": [
    "## Model Training \n",
    "----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429ec787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Model - Refer to documentation on `dcgan.start_or_resume_training_run` for details\n",
    "result = dcgan.start_or_resume_training_run(\n",
    "    dataloader, train_cfg, model_cfg, n_epochs=64, st_epoch=0\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
