{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "897d036b",
   "metadata": {},
   "source": [
    "# DCGAN - Supplemental Media and Figures\n",
    "\n",
    "Contains supplemental media and figures, currently includes the following:\n",
    "\n",
    "- Training Progress Video \n",
    "- Training Progress Gif\n",
    "- Training Loss\n",
    "- CPU Generated Samples\n",
    "\n",
    "--------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e36995",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Install ffmpeg - Probably Not on Kernel by Default\n",
    "! pip3 install \\\n",
    "    ffmpeg \\\n",
    "    tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b13656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Deps\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Plotting + Video\n",
    "import ffmpeg\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "# Torch\n",
    "import torch\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "# DCGAN\n",
    "import msls.dcgan_utils as utils\n",
    "import msls.gpu_dcgan as dcgan\n",
    "from msls.gan import Generator, Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df14244a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arguments - Set as Desired\n",
    "EPOCH = 1\n",
    "\n",
    "# Init Model and Training Configs w. Default Values\n",
    "model_cfg = utils.ModelCheckpointConfig(\n",
    "    name=\"south-beach\", # Custom Model Name To Identify Gaudi vs GPU trained\n",
    "    root=\"/efs/trained_model\",\n",
    "    save_frequency=1,\n",
    "    log_frequency=50,\n",
    "    gen_progress_frequency=250,\n",
    ")\n",
    "\n",
    "train_cfg = utils.TrainingConfig(\n",
    "    dev=torch.device(\"cpu\"),\n",
    "    batch_size=128,\n",
    "    img_size=64,\n",
    "    nc=3,\n",
    "    nz=100,\n",
    "    ngf=64,\n",
    "    ndf=64,\n",
    "    lr=0.0002,\n",
    "    beta1=0.5,\n",
    "    beta2=0.999,\n",
    "    data_root=\"/efs/imgs/test/miami\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854c85dc",
   "metadata": {},
   "source": [
    "## Get Model Checkpoint For Evaluation\n",
    "---------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b24f6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = utils.get_checkpoint(\n",
    "    path = f\"{model_cfg.root}/{model_cfg.name}/checkpoint_{EPOCH}.pt\",\n",
    "    cpu = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f13e73",
   "metadata": {},
   "source": [
    "## Figure 1.1 - `G` and `D` Training Losses\n",
    "\n",
    "-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b22d07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Training Losses to the Generator (G) and Discriminator (D)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.title(f\"Generator and Discriminator Loss During Training - {model_cfg.name}\")\n",
    "plt.plot(checkpoint[\"losses\"][\"_G\"], label=\"G\")\n",
    "plt.plot(checkpoint[\"losses\"][\"_D\"], label=\"D\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Save to Disk\n",
    "plt.savefig(\n",
    "    f\"{model_cfg.root}/{model_cfg.name}/figures/train_loss.png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082f4087",
   "metadata": {},
   "source": [
    "## Figure 2.1.1 - Final Images of Fixed Noise Sample vs Real Images\n",
    "\n",
    "Get a batch of real images from the dataloader and compare the final generated images vs. the real images. Do they hold up against human discretion? Note that this figure uses fixed noise saved as part of the model checkpoint and will **NOT** generate new images from `G` on subsequent runs.\n",
    "\n",
    "--------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea42eb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = dcgan.get_msls_dataloader(0, train_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5832c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_batch = next(iter(dataloader))\n",
    "\n",
    "# Plot the real images from the dataloader \n",
    "plt.figure(figsize=(15, 15))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Real Images\")\n",
    "plt.imshow(\n",
    "    np.transpose(\n",
    "        vutils.make_grid(\n",
    "            real_batch[0].to(train_cfg.dev)[:64], padding=5, normalize=True\n",
    "        ).cpu(),\n",
    "        (1, 2, 0),\n",
    "    )\n",
    ")\n",
    "\n",
    "# Plot the fake images from the final epoch of `G`\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Generated Images\")\n",
    "plt.imshow(np.transpose(img_list[-1], (1, 2, 0)))\n",
    "plt.show()\n",
    "\n",
    "plt.savefig(\n",
    "    f\"{model_cfg.root}/{model_cfg.name}/figures/compare_{PLOT_DTTM}.png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6448d3",
   "metadata": {},
   "source": [
    "## Figure 2.1.2 - Training Progress Sequence on Fixed Noise\n",
    "\n",
    "In each epoch (or at some fixed interval, e.g. every other, every third) during training the model saved the progress of `G` on transforming a series of fixed inputs, `Z`. This figure shows the progress of `Z` as the model trained.\n",
    "\n",
    "----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3644ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1.2 - Training Progress Sequence Saved as video && GIF\n",
    "\n",
    "ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=150, blit=True)\n",
    "\n",
    "writergif = animation.PillowWriter(\n",
    "    fps=10, metadata=dict({\"title\": f\"{model_cfg.name}\"}, **model_cfg.__dict__)\n",
    ")\n",
    "\n",
    "# Save GIF\n",
    "ani.save(\n",
    "    f\"{model_cfg.root}/{model_cfg.name}/videos/progress_{PLOT_DTTM}.gif\",\n",
    "    writer=writergif,\n",
    ")\n",
    "\n",
    "# Save Video\n",
    "with open(\n",
    "    f\"{model_cfg.root}/{model_cfg.name}/videos/progress_{PLOT_DTTM}.html\", \"w\",\n",
    ") as fi:\n",
    "    print(ani.to_html5_video(), file=fi)\n",
    "\n",
    "# Show Video - Note; this can get quite large if there are too many frames or too many fixed\n",
    "# noise images saved along with the model's progress checkpoints...\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d447fcf2",
   "metadata": {},
   "source": [
    "## Figure 3.1 - Generate New Samples From CPU\n",
    "\n",
    "This figure generates novel images from `G` by creating a new input vector `Z` and feeding it through the network. Because `Z` is regenerated on each run, these results will vary between executions.\n",
    "\n",
    "Being able to run \"inference\" quickly is important. Ideally `G` can generate samples using just the CPU. Using `G` to generate samples on the CPU allows us to serve new imaages off an inexpensive instance.\n",
    "\n",
    "-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0942ca92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 3.1 - Generate New Samples From CPU\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "\n",
    "# Create a new TrainingConfig which will generate noise on the CPU\n",
    "train_cfg_cpu_only = dcgan.TrainingConfig(dev=torch.device(\"cpu\"))\n",
    "\n",
    "# Generate Samples from `G` (again, on CPU)\n",
    "imgs = dcgan.generate_fake_samples(\n",
    "    n_samples=4, train_cfg=train_cfg_cpu_only, model_cfg=model_cfg, as_of_epoch=EPOCH\n",
    ")\n",
    "\n",
    "# Plot results\n",
    "plt.imshow(\n",
    "    np.transpose(\n",
    "        vutils.make_grid(imgs.to(train_cfg.dev), padding=2, normalize=True).cpu(),\n",
    "        (1, 2, 0),\n",
    "    )\n",
    ")\n",
    "\n",
    "# Save Result\n",
    "plt.savefig(\n",
    "    f\"{model_cfg.root}/{model_cfg.name}/figures/novel_samples_{PLOT_DTTM}.png\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
