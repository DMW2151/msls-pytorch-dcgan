{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "897d036b",
   "metadata": {},
   "source": [
    "# DCGAN - Supplemental Media and Figures\n",
    "\n",
    "Contains supplemental media and figures, currently includes the following:\n",
    "\n",
    "- Training Progress Video \n",
    "- Training Progress Gif\n",
    "- Training Loss\n",
    "- CPU Generated Samples\n",
    "\n",
    "--------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b13656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Deps\n",
    "import os\n",
    "import re\n",
    "import datetime\n",
    "import numpy as np\n",
    "\n",
    "# Plotting + Video\n",
    "import ffmpeg\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "# DCGAN\n",
    "import gaudi_dcgan as dcgan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d28c4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Start Datetime for plots; apply all the way through the Notebook\n",
    "PLOT_DTTM = re.sub(\":|-| |\\.\", \"_\", datetime.datetime.utcnow().__str__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df14244a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init Model and Training Configs w. Default Values - See gaudi_dcgan.py for descriptions. For clarity,\n",
    "# objects below are initialized with their default values.\n",
    "model_cfg = dcgan.ModelCheckpointConfig(\n",
    "    batch_size=128,\n",
    "    img_size=64,\n",
    "    nc=3,\n",
    "    nz=100,\n",
    "    ngf=64,\n",
    "    ndf=64,\n",
    "    lr=0.0002,\n",
    "    beta1=0.5,\n",
    "    beta2=0.999,\n",
    ")\n",
    "\n",
    "train_cfg = dcgan.TrainingConfig(\n",
    "    model_name=\"msls_dcgan_ml_p3_8xlarge_001\", # Custom Model Name To Identify Gaudi vs GPU trained\n",
    "    model_dir=\"/efs/trained_model\",\n",
    "    save_frequency=1,\n",
    "    log_frequency=50,\n",
    "    gen_progress_frequency=250,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ce276c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Figures and Videos Directory if Not Yet Exists...\n",
    "if not os.path.exists(f\"{model_cfg.model_dir}/{model_cfg.model_name}/figures\"):\n",
    "    os.makedirs(f\"{model_cfg.model_dir}/{model_cfg.model_name}/figures\")\n",
    "\n",
    "if not os.path.exists(f\"{model_cfg.model_dir}/{model_cfg.model_name}/videos\"):\n",
    "    os.makedirs(f\"{model_cfg.model_dir}/{model_cfg.model_name}/videos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f13e73",
   "metadata": {},
   "source": [
    "## Figure 1.1 - `G` and `D` Training Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b22d07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Training Losses to the Generator (G) and Discriminator (D)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.title(f\"Generator and Discriminator Loss During Training - {model_cfg.model_name}\")\n",
    "plt.plot(result[\"losses\"][\"_G\"], label=\"G\")\n",
    "plt.plot(result[\"losses\"][\"_D\"], label=\"D\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.savefig(\n",
    "    f\"{model_cfg.model_dir}/{model_cfg.model_name}/figures/train_loss_{plots_execution_dttm}.png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fe3e9f",
   "metadata": {},
   "source": [
    "## Figure 2.1.1 - Final Images of Fixed Noise Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a96d36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a Graphic of the Final images...\n",
    "\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "plt.axis(\"off\")\n",
    "\n",
    "# Create a Frame for each epoch from results.img_list\n",
    "ims = [\n",
    "    [plt.imshow(np.transpose(i, (1, 2, 0)), animated=True)] for i in result[\"img_list\"]\n",
    "]\n",
    "\n",
    "# 2.1.1 Final Images of Fixed Noise Sample\n",
    "plt.savefig(\n",
    "    f\"{model_cfg.model_dir}/{model_cfg.model_name}/figures/generaed_{plots_execution_dttm}.png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d663fa",
   "metadata": {},
   "source": [
    "## Figure 2.1.2 - Training Progress Sequence on Fixed Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e8f144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1.1 - Training Progress Sequence Saved as Video\n",
    "\n",
    "ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)\n",
    "\n",
    "content = HTML(ani.to_jshtml())\n",
    "\n",
    "writergif = animation.PillowWriter(\n",
    "    fps=10, metadata=dict({\"title\": f\"{model_cfg.model_name}\"}, **model_cfg.__dict__)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70544f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Animation as Gif and as HTML w. Video...\n",
    "ani.save(\n",
    "    f\"{model_cfg.model_dir}/{model_cfg.model_name}/videos/progress_{plots_execution_dttm}.gif\",\n",
    "    writer=writergif,\n",
    ")\n",
    "\n",
    "with open(\n",
    "    f\"{model_cfg.model_dir}/{model_cfg.model_name}/videos/progress_{plots_execution_dttm}.html\",\n",
    "    \"w\",\n",
    ") as fi:\n",
    "    print(ani.to_html5_video(), file=fi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa217291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab a batch of real images from the dataloader and compare the final Generated images vs the Real\n",
    "# images. Do they hold up against human discretion?\n",
    "\n",
    "real_batch = next(iter(dataloader))\n",
    "\n",
    "# Plot the real images\n",
    "plt.figure(figsize=(15, 15))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Real Images\")\n",
    "plt.imshow(\n",
    "    np.transpose(\n",
    "        vutils.make_grid(\n",
    "            real_batch[0].to(train_cfg.dev)[:64], padding=5, normalize=True\n",
    "        ).cpu(),\n",
    "        (1, 2, 0),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd3b0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the fake images from the final epoch\n",
    "# NOTE: This uses the fixed noise from the trained model and is not variable between executions\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Generated Images\")\n",
    "plt.imshow(np.transpose(result[\"img_list\"][-1], (1, 2, 0)))\n",
    "plt.show()\n",
    "\n",
    "plt.savefig(\n",
    "    f\"{model_cfg.model_dir}/{model_cfg.model_name}/figures/compare_{plots_execution_dttm}.png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ef9005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a few sample images; this is using randomly generated noise\n",
    "# and results should be variable across multiple runs...\n",
    "# Experiment: Ideally a Generator Net can use a CPU to (slowly) generate samples, being able to move\n",
    "# the G network off GPU/HPU allows us to serve imgs off an inexpensive webserver. In this case we generator\n",
    "# noise AND images on the CPU\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "\n",
    "# generated_data[0].shape == torch.Size([3, 64, 64])\n",
    "train_cfg_cpu_only = dcgan.TrainingConfig(dev=torch.device(\"cpu\"))\n",
    "\n",
    "imgs = dcgan.generate_fake_samples(\n",
    "    n_samples=4, train_cfg=train_cfg_cpu_only, model_cfg=model_cfg, as_of_epoch=4\n",
    ")\n",
    "\n",
    "\n",
    "plt.imshow(\n",
    "    np.transpose(\n",
    "        vutils.make_grid(imgs.to(train_cfg.dev), padding=2, normalize=True).cpu(),\n",
    "        (1, 2, 0),\n",
    "    )\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
