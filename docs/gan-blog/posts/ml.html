<!doctype html>
<html lang="en">
  <head>
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <link rel="shortcut icon" href="favicon.ico" type="image/x-icon"> 
    <meta charset="utf-8">
    <meta name="author" content='Dustin Wilson'>
    <meta name="date" content='2022-02-08'>
    <title>DCGAN - Modeling Considerations</title>
    <style>
            html {
              line-height: 1.5;
              font-family: Georgia, serif;
              font-size: 16px;
              color: #1a1a1a;
              background-color: #202025;
            }
            .header {
              text-align: center;
              background: gray;
              color: white;
            }
            strong {
              color: #5858d9;
            }
            body {
              margin: 0 auto;
              max-width: 52em;
              padding-left: 50px;
              padding-right: 50px;
              padding-top: 50px;
              padding-bottom: 50px;
              hyphens: auto;
              overflow-wrap: break-word;
              text-rendering: optimizeLegibility;
              font-kerning: normal;
            }
            @media (max-width: 600px) {
              body {
                font-size: 0.9em;
                padding: 1em;
              }
            }
            @media print {
              body {
                background-color: transparent;
                color: black;
                font-size: 12pt;
              }
              p, h2, h3 {
                orphans: 3;
                widows: 3;
              }
              h2, h3, h4 {
                page-break-after: avoid;
              }
            }
            p {
              margin: 1em 0;
            }
            a {
              color: #5858d9;
            }
            a:visited {
              color: #9292f2;
            }
            img {
              max-width: 600px;
            }
            h1, h2, h3, h4, h5, h6 {
              margin-top: 1.4em;
            }
            h5, h6 {
              font-size: 1em;
              font-style: italic;
            }
            h6 {
              font-weight: normal;
            }
            ol, ul {
              padding-left: 1.7em;
              margin-top: 1em;
            }
            li > ol, li > ul {
              margin-top: 0;
            }
            blockquote {
              margin: 1em 0 1em 1.7em;
              padding-left: 1em;
              border-left: 2px solid #e6e6e6;
            }
            mark {
              background: lightgoldenrodyellow
            }
            code {
              font-family: Menlo, Monaco, 'Lucida Console', Consolas, monospace;
              font-size: 85%;
              margin: 0;
              color: #FFFBC8;
            }
            pre {
              margin: 1em 0;
              overflow: auto;
            }
            pre code {
              padding: 0;
              overflow: visible;
              overflow-wrap: normal;
              color: #ebebe6;
            }
            .sourceCode {
             background-color: #151515;
             overflow: visible;
            }
            hr {
              background-color: #ebebe6;
              border: none;
              height: 2px;
              margin: 1em 0;
            }
            .gan-test-img {
              transition: background-color .2s;
            }
            .gan-test-img:hover {
              mix-blend-mode: hard-light;
              width: min-content;
            }
            table {
              margin: 1em 0;
              border-collapse: collapse;
              text-align: center;
              width: 60%;
              overflow-x: auto;
              font-variant-numeric: lining-nums tabular-nums;
              color: #ebebe6;
              margin-left: auto;
              margin-right: auto;
            }
            table caption {
              margin-bottom: 0.75em;
            }
            tbody {
              margin-top: 0.5em;
              /*border-top: 1px solid #ebebe6;*/
              /*border-bottom: 1px solid #ebebe6;*/
              margin-left: auto;
              margin-right: auto;
            }
            th {
              border-top: 1px solid #202025;
              padding: 0.25em 0.5em 0.25em 0.5em;
            }
            td {
              padding: 0.125em 0.5em 0.25em 0.5em;
              color: #ebebe6;
            }
            header {
              margin-bottom: 4em;
              text-align: center;
            }
            #TOC li {
              list-style: none;
            }
            #TOC a:not(:hover) {
              text-decoration: none;
            }
            code{white-space: pre-wrap;}
            span.smallcaps{font-variant: small-caps;}
            span.underline{text-decoration: underline;}
            div.column{display: inline-block; vertical-align: top; width: 50%;}
            div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
            ul.task-list{list-style: none;}
            pre > code.sourceCode { white-space: pre; position: relative; }
            pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
            pre > code.sourceCode > span:empty { height: 1.2em; }
            .sourceCode { overflow: visible; }
            code.sourceCode > span { color: inherit; text-decoration: inherit; }
            div.sourceCode { margin: 1em 0; }
            pre.sourceCode { margin: 0; }
            @media screen {
            div.sourceCode { overflow: auto; }
            }
            @media print {
            pre > code.sourceCode { white-space: pre-wrap; }
            pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
            }
            pre.numberSource code
              { counter-reset: source-line 0; }
            pre.numberSource code > span
              { position: relative; left: -4em; counter-increment: source-line; }
            pre.numberSource code > span > a:first-child::before
              { content: counter(source-line);
                position: relative; left: -1em; text-align: right; vertical-align: baseline;
                border: none; display: inline-block;
                -webkit-touch-callout: none; -webkit-user-select: none;
                -khtml-user-select: none; -moz-user-select: none;
                -ms-user-select: none; user-select: none;
                padding: 0 4px; width: 4em;
                color: #FFFBC8;
              }
            pre.numberSource { margin-left: 3em; border-left: 1px solid #FFFBC8;  padding-left: 4px; }
            div.sourceCode
              {   }
            @media screen {
            pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
            }
            code span.al { color: #FFFBC8; font-weight: bold; } /* Alert */
            code span.an { color: #FFFBC8; font-weight: bold; font-style: italic; } /* Annotation */
            code span.at { color: #FFFBC8; } /* Attribute */
            code span.bn { color: #FFFBC8; } /* BaseN */
            code span.bu { } /* BuiltIn */
            code span.cf { color: #FFFBC8; font-weight: bold; } /* ControlFlow */
            code span.ch { color: #FFFBC8; } /* Char */
            code span.cn { color: #FFFBC8; } /* Constant */
            code span.co { color: #FFFBC8; font-style: italic; } /* Comment */
            code span.cv { color: #FFFBC8; font-weight: bold; font-style: italic; } /* CommentVar */
            code span.do { color: #FFFBC8; font-style: italic; } /* Documentation */
            code span.dt { color: #FFFBC8; } /* DataType */
            code span.dv { color: #FFFBC8; } /* DecVal */
            code span.er { color: #FFFBC8; font-weight: bold; } /* Error */
            code span.ex { } /* Extension */
            code span.fl { color: #FFFBC8; } /* Float */
            code span.fu { color: #FFFBC8; } /* Function */
            code span.im { } /* Import */
            code span.in { color: #FFFBC8; font-weight: bold; font-style: italic; } /* Information */
            code span.kw { color: #FFFBC8; font-weight: bold; } /* Keyword */
            code span.op { color: #FFFBC8; } /* Operator */
            code span.ot { color: #FFFBC8; } /* Other */
            code span.pp { color: #FFFBC8; } /* Preprocessor */
            code span.sc { color: #FFFBC8; } /* SpecialChar */
            code span.ss { color: #FFFBC8; } /* SpecialString */
            code span.st { color: #FFFBC8; } /* String */
            code span.va { color: #FFFBC8; } /* Variable */
            code span.vs { color: #FFFBC8; } /* VerbatimString */
            code span.wa { color: #FFFBC8; font-weight: bold; font-style: italic; } /* Warning */
            .display.math{display: block; text-align: center; margin: 0.5rem auto;}
          </style>
  </head>
  <body style="background-color:#202025; color: #e6e6e6"></body>
    <header>
        <div style="background-color:#202025; color: #e6e6e6" class="header">
            <a href="./trained-a-gan.html" style="padding: 10px; font-size: 12px;">Project Overview</a>
            <a href="./ml.html" style="padding: 10px; font-size: 12px;">Details on Model Development</a>
            <a href="./infra.html" style="padding: 10px; font-size: 12px;">Details on Infrastructure & Performance</a>
            <a href="./gan-training-notes.html" style="padding: 10px; font-size: 12px;">Model User Guide</a>
            <a href="./gallery.html" style="padding: 10px; font-size: 12px;">Gallery</a>
        </div>
    </header>
    <h1> DCGAN - Modeling Considerations </h1>
    <p>Dustin Wilson &#8212 February 8, 2022</p>
    <hr>
    <h2 id="general-improvements">General Improvements</h2>
    <p>I want to stress that this isn’t a strict replication of the original DCGAN papers. At a low-level, it’s difficult to describe all of the internal consequences of using <code>PyTorch</code> rather than the specific packages the authors used. At a high level, I made the following notable changes:</p>
    <ul>
    <li><p><strong>Use a Different Optimizer</strong> — Choose <code>AdamW</code>/<code>FusedAdamW</code> as an optimizer function over <code>SGD</code>. <em>Goodfellow, et al.</em> use a custom <code>SGD</code> <a href="https://github.com/goodfeli/adversarial/blob/master/sgd.py">implementation</a> that is a patched version of pylearn2’s <code>SGD</code>. Instead, I elected for a built-in PyTorch optimizer, <code>AdamW</code>. As an added benefit, Habana offers their own <code>FusedAdamW</code> implementation that should perform quite well on the Gaudi instances.</p></li>
    <li><p><strong>Increase The Size of the Generator Feature Map</strong> — I increase the depth of the Generator feature map so that <code>G</code>’s depth outnumbered <code>D</code>’s 4-to-1. This is a balancing act; because the images are so small, a large enough parameter space could easily over-fit on the sample data. Additionally, the original model was <em>very</em> small, so increasing the size allows the HPU the opportunity to excel a bit.</p></li>
    <li><p><strong>Remove the Sigmoid From the Discriminator</strong> — This one sounds more controversial than it is. Typically a binary classification problem like the one <code>D</code> solves would use <a href="https://en.wikipedia.org/wiki/Cross_entropy">Binary Cross Entropy Loss</a> (<code>BCELoss</code>). The way that PyTorch optimizes for mixed-precision operations required I switch to <code>BCEWithLogitLoss</code>, a loss function that expects logits (<code>L∈(−∞,∞)</code>) rather than probabilities (<code>p∈[0,1]</code>). In effect, this change moves the <code>Sigmoid</code> from the network to part of the loss function.</p></li>
    <li><p><strong>Add an Additional Convolutional Block</strong> — I add an additional block of <code>Conv2d</code>, <code>BatchNorm2d</code>, and <code>Relu</code> layers to start the model. This allows me to handle for images at <code>(3 x 128 x 128)</code>, although getting stable training on these larger images took a bit of tuning, it was an interesting challenge to reason through all of this.</p></li>
    </ul>
    <h2 id="selecting-parameters-for-stability">Selecting Parameters for Stability</h2>
    <p>DCGAN can be unstable in comparison to modern generative models. The most common failure mode I observed involved was <code>D</code> learning the difference between test and real images too quickly (e.g. some property of fake images that made them easy to identify), and that left <code>G</code> to make trivial progress in generating better images over time. I didn’t have the time or resources to do full hyper-parameter tuning, so I used a few <del>tricks</del> heuristics suggested <a href="https://github.com/pytorch/examples/issues/70">here</a> and <a href="https://github.com/soumith/ganhacks">here</a> to stabilize the model.</p>
    <p>After some experimentation and consulting the literature<sup>1</sup>, I landed on the following parameters for my <code>Safe-Params</code> scenario. All of these choices are meant to be conservative in that they forsake optimal performance or faster model-convergence time in favor of stability of results. At the same time, I wasn’t hoping to train a 1B parameter model for ages. Again, this is a balancing act.</p>
    <ul>
    <li><strong>Additional Noise Layer in Transformations</strong> — (0, 0.2)</li>
    <li><strong>Batch Size</strong> — 512</li>
    <li><strong>Learning Rate</strong> — 0.0002</li>
    <li><strong>Generator Feature Map Depth</strong> — 128</li>
    <li><strong>Discriminator Feature Map Depth</strong> — 32</li>
    <li><strong>Latent Vector Size</strong> — 128</li>
    <li><strong>Adam Optimizer w. Weight Decay:</strong> — 0.05</li>
    </ul>
    <p>For reference, setting the noise value high can produce grainy results, but in practice, it’s an effective remedy against the generator collapsing (see: <a href="https://www.inference.vc/instance-noise-a-trick-for-stabilising-gan-training/"><em>Amortised MAP Inference for Image Super-resolution</em></a><sup>1</sup>). I disabled the noise layer on <code>DL1</code> instances to enable the <code>Habana.DataLoader</code> in lieu of the built-in <code>PyTorch.dataloader</code>.</p>
    <h2 id="evaluating-gan-performance">Evaluating GAN Performance</h2>
    <p>Evaluating GANs is difficult because there’s no objective loss function for the results of the Generator. In <em>Goodfellow, et al.</em>, the authors use Parzen Kernel-Density-Estimation to evaluate their architecture against other generative methods. In the years since, this method has been revealed to suffer from quite a few problems.</p>
    <blockquote>
    <p>Parzen windows estimation of likelihood favors trivial models and is irrelevant to visual fidelity of samples. Further, it fails to approximate the true likelihood in high dimensional spaces or to rank models<sup>2</sup></p>
    </blockquote>
    <p>Other authors<sup>3</sup> suggest alternative methods, though the most common ones rely on the existence of a pre-trained classifier model. A GAN that generates identifiable objects, (e.g. horses, faces, tea-kettles) might be better for these methods than my GAN. For completeness sake, I implemented and tested Parzen KDE as described in the paper, but found middling results. It didn’t seem to add much more over the <code>G</code> and <code>D</code> loss functions and I really couldn’t verify the validity of the metric. Consider the neg-log-likelihood plot from this 16 epoch training run. Following the first epoch, which was mostly white noise, the metric is largely unchanged through the remainder of the run.</p>
    <table>
    <tbody>
    <tr class="odd">
    <td style="text-align: center;"><em>Experimental Output - Plot of Negative Log Likelihood Thru 16 Epochs</em></td>
    </tr>
    <tr class="even">
    <td style="text-align: center;"><img src="../images/training/parzen.png" alt="OK" /></td>
    </tr>
    </tbody>
    </table>
    <p>Am I to interpret this as the generator failing to improve after the third epoch? Or perhaps even got worse as training progressed beyond the 5th? Because I got uncertain results here and the best alternatives (i.e. inception models) weren’t well suited to my problem, I abandoned quantitative GAN evaluation here.</p>
    <hr />
    <h2 id="references">References</h2>
    <p><strong><sup>1</sup></strong> <em>Sønderby, Casper Kaae, et al. “Amortised map inference for image super-resolution.” arXiv preprint arXiv:1610.04490 (2016).</em></p>
    <p><strong><sup>2</sup></strong> <em>Borji, Ali. “Pros and cons of gan evaluation measures.” Computer Vision and Image Understanding 179 (2019): 41-65.</em></p>
    <p><strong><sup>3</sup></strong> <em>Salimans, Tim, et al. “Improved techniques for training gans.” Advances in neural information processing systems 29 (2016).</em></p>
    <footer class="site-footer">
        <span class="site-footer-owner"> Maintained by <a href="https://github.com/DMW2151">DMW2151</a>.</span>
    </footer>
  </body>
</html>
