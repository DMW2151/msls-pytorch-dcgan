<!doctype html>
<html lang="en">
  <head>
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <link rel="shortcut icon" href="favicon.ico" type="image/x-icon"> 
    <meta charset="utf-8">
    <meta name="author" content='Dustin Wilson'>
    <meta name="date" content='2022-02-08'>
    <title>Model Training Notes</title>
    <style>
            html {
              line-height: 1.5;
              font-family: Georgia, serif;
              font-size: 16px;
              color: #1a1a1a;
              background-color: #202025;
            }
            .header {
              text-align: center;
              background: gray;
              color: white;
            }
            strong {
              color: #5858d9;
            }
            body {
              margin: 0 auto;
              max-width: 52em;
              padding-left: 50px;
              padding-right: 50px;
              padding-top: 50px;
              padding-bottom: 50px;
              hyphens: auto;
              overflow-wrap: break-word;
              text-rendering: optimizeLegibility;
              font-kerning: normal;
            }
            @media (max-width: 600px) {
              body {
                font-size: 0.9em;
                padding: 1em;
              }
            }
            @media print {
              body {
                background-color: transparent;
                color: black;
                font-size: 12pt;
              }
              p, h2, h3 {
                orphans: 3;
                widows: 3;
              }
              h2, h3, h4 {
                page-break-after: avoid;
              }
            }
            p {
              margin: 1em 0;
            }
            a {
              color: #5858d9;
            }
            a:visited {
              color: #9292f2;
            }
            img {
              max-width: 600px;
            }
            h1, h2, h3, h4, h5, h6 {
              margin-top: 1.4em;
            }
            h5, h6 {
              font-size: 1em;
              font-style: italic;
            }
            h6 {
              font-weight: normal;
            }
            ol, ul {
              padding-left: 1.7em;
              margin-top: 1em;
            }
            li > ol, li > ul {
              margin-top: 0;
            }
            blockquote {
              margin: 1em 0 1em 1.7em;
              padding-left: 1em;
              border-left: 2px solid #e6e6e6;
            }
            mark {
              background: lightgoldenrodyellow
            }
            code {
              font-family: Menlo, Monaco, 'Lucida Console', Consolas, monospace;
              font-size: 85%;
              margin: 0;
              color: #FFFBC8;
            }
            pre {
              margin: 1em 0;
              overflow: auto;
            }
            pre code {
              padding: 0;
              overflow: visible;
              overflow-wrap: normal;
              color: #ebebe6;
            }
            .sourceCode {
             background-color: #151515;
             overflow: visible;
            }
            hr {
              background-color: #ebebe6;
              border: none;
              height: 2px;
              margin: 1em 0;
            }
            .gan-test-img {
              transition: background-color .2s;
            }
            .gan-test-img:hover {
              mix-blend-mode: hard-light;
              width: min-content;
            }
            table {
              margin: 1em 0;
              border-collapse: collapse;
              text-align: center;
              width: 60%;
              overflow-x: auto;
              font-variant-numeric: lining-nums tabular-nums;
              color: #ebebe6;
              margin-left: auto;
              margin-right: auto;
            }
            table caption {
              margin-bottom: 0.75em;
            }
            tbody {
              margin-top: 0.5em;
              /*border-top: 1px solid #ebebe6;*/
              /*border-bottom: 1px solid #ebebe6;*/
              margin-left: auto;
              margin-right: auto;
            }
            th {
              border-top: 1px solid #202025;
              padding: 0.25em 0.5em 0.25em 0.5em;
            }
            td {
              padding: 0.125em 0.5em 0.25em 0.5em;
              color: #ebebe6;
            }
            header {
              margin-bottom: 4em;
              text-align: center;
            }
            #TOC li {
              list-style: none;
            }
            #TOC a:not(:hover) {
              text-decoration: none;
            }
            code{white-space: pre-wrap;}
            span.smallcaps{font-variant: small-caps;}
            span.underline{text-decoration: underline;}
            div.column{display: inline-block; vertical-align: top; width: 50%;}
            div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
            ul.task-list{list-style: none;}
            pre > code.sourceCode { white-space: pre; position: relative; }
            pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
            pre > code.sourceCode > span:empty { height: 1.2em; }
            .sourceCode { overflow: visible; }
            code.sourceCode > span { color: inherit; text-decoration: inherit; }
            div.sourceCode { margin: 1em 0; }
            pre.sourceCode { margin: 0; }
            @media screen {
            div.sourceCode { overflow: auto; }
            }
            @media print {
            pre > code.sourceCode { white-space: pre-wrap; }
            pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
            }
            pre.numberSource code
              { counter-reset: source-line 0; }
            pre.numberSource code > span
              { position: relative; left: -4em; counter-increment: source-line; }
            pre.numberSource code > span > a:first-child::before
              { content: counter(source-line);
                position: relative; left: -1em; text-align: right; vertical-align: baseline;
                border: none; display: inline-block;
                -webkit-touch-callout: none; -webkit-user-select: none;
                -khtml-user-select: none; -moz-user-select: none;
                -ms-user-select: none; user-select: none;
                padding: 0 4px; width: 4em;
                color: #FFFBC8;
              }
            pre.numberSource { margin-left: 3em; border-left: 1px solid #FFFBC8;  padding-left: 4px; }
            div.sourceCode
              {   }
            @media screen {
            pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
            }
            code span.al { color: #FFFBC8; font-weight: bold; } /* Alert */
            code span.an { color: #FFFBC8; font-weight: bold; font-style: italic; } /* Annotation */
            code span.at { color: #FFFBC8; } /* Attribute */
            code span.bn { color: #FFFBC8; } /* BaseN */
            code span.bu { } /* BuiltIn */
            code span.cf { color: #FFFBC8; font-weight: bold; } /* ControlFlow */
            code span.ch { color: #FFFBC8; } /* Char */
            code span.cn { color: #FFFBC8; } /* Constant */
            code span.co { color: #FFFBC8; font-style: italic; } /* Comment */
            code span.cv { color: #FFFBC8; font-weight: bold; font-style: italic; } /* CommentVar */
            code span.do { color: #FFFBC8; font-style: italic; } /* Documentation */
            code span.dt { color: #FFFBC8; } /* DataType */
            code span.dv { color: #FFFBC8; } /* DecVal */
            code span.er { color: #FFFBC8; font-weight: bold; } /* Error */
            code span.ex { } /* Extension */
            code span.fl { color: #FFFBC8; } /* Float */
            code span.fu { color: #FFFBC8; } /* Function */
            code span.im { } /* Import */
            code span.in { color: #FFFBC8; font-weight: bold; font-style: italic; } /* Information */
            code span.kw { color: #FFFBC8; font-weight: bold; } /* Keyword */
            code span.op { color: #FFFBC8; } /* Operator */
            code span.ot { color: #FFFBC8; } /* Other */
            code span.pp { color: #FFFBC8; } /* Preprocessor */
            code span.sc { color: #FFFBC8; } /* SpecialChar */
            code span.ss { color: #FFFBC8; } /* SpecialString */
            code span.st { color: #FFFBC8; } /* String */
            code span.va { color: #FFFBC8; } /* Variable */
            code span.vs { color: #FFFBC8; } /* VerbatimString */
            code span.wa { color: #FFFBC8; font-weight: bold; font-style: italic; } /* Warning */
            .display.math{display: block; text-align: center; margin: 0.5rem auto;}
          </style>
  </head>
  <body style="background-color:#202025; color: #e6e6e6"></body>
    <header>
        <div style="background-color:#202025; color: #e6e6e6" class="header">
            <a href="./trained-a-gan.html" style="padding: 10px; font-size: 12px;">Project Overview</a>
            <a href="./ml.html" style="padding: 10px; font-size: 12px;">Details on Model Development</a>
            <a href="./infra.html" style="padding: 10px; font-size: 12px;">Details on Infrastructure & Performance</a>
            <a href="./gan-training-notes.html" style="padding: 10px; font-size: 12px;">Model User Guide</a>
            <a href="./gallery.html" style="padding: 10px; font-size: 12px;">Gallery</a>
        </div>
    </header>
    <h1> Model Training Notes </h1>
    <p>Dustin Wilson &#8212 February 8, 2022</p>
    <hr>
    <p>This section is included along with my <a href="./trained-a-gan.html">main post</a> to serve as a user guide for those interested in training their own GANs with the code presented <a href="https://github.com/DMW2151/msls-pytorch-dcgan">here</a>.</p>
    <h2 id="infrastructure">Infrastructure</h2>
    <h3 id="setting-up-the-full-infrastructure">Setting Up The Full Infrastructure</h3>
    <p><strong>NOTICE:</strong> — This module deploys live resources into your AWS account, please be mindful of the costs associated with those resources. This module does not download (nor provision pipelines to download) MSLS data, but you may access it from <a href="https://www.mapillary.com/datasets">Mapillary</a>.</p>
    <p>All infrastructure for the project is available <a href="https://github.com/DMW2151/msls-dcgan-infra">here</a> and should be readily accessible if you’re familiar with Terraform. If you’re not comfortable with Terraform, I would recommend reading Hashicorp’s intro to <a href="https://learn.hashicorp.com/collections/terraform/aws-get-started">Terraform on AWS</a> to make sure you’re <strong>safely</strong> deploying resources to your account.</p>
    <p>If you are familiar with Terraform, I’d ask that you still be quite cautious. This module deploys resources that can easily top a few hundred dollars / day if left unattended (mostly the <code>DL1</code> instance, but SageMaker and EBS can add up, too). Keep the following in mind:</p>
    <p>Remember to:</p>
    <ul>
    <li>Change the Terraform statefile’s S3-backend to a bucket you own!</li>
    <li>Change regions and AZs to launch the training instance to one with <code>DL1</code> instances available!</li>
    </ul>
    <h3 id="model-training-infra-only">Model Training Infra Only</h3>
    <p>If you’re just interested in training a GAN, I would recommend spinning up a single <code>DL1</code> instance, cloning the model <a href="https://github.com/DMW2151/msls-pytorch-dcgan">repo</a>, and pip installing the training package with <code>pip install -e /path/to/msls/package/model/</code>. From there, you should be ready to train on any data local to that instance.</p>
    <p><strong>NOTE:</strong> — If you’re using a modern GPU or HPU, I would suggest training on the best disk available to your instance. On the <code>DL1</code>, I saw a meaningful performance improvement from using ephemeral NVME storage over the GP3 volume.</p>
    <hr />
    <h2 id="data-preparation">Data Preparation</h2>
    <p>The MSLS data is available for download <a href="https://www.mapillary.com/dataset/places">here</a>. Please note that since December they’ve had <a href="https://github.com/mapillary/mapillary_sls/issues/23">sporadic performance</a> on their download site. The data is available in batches, and at the very least Batch 6 (1.6 GB compressed) should download without issue. You should not attempt to access the data programmatically. Once you agree to the Mapillary TOS you’ll receive a signed URL for each batch. I used the following to download and unzip each batch to instance storage.</p>
    <div class="sourceCode" id="cb1"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>    <span class="co">#! /bin/bash</span></span>
    <span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="ex">curl</span> <span class="at">-k</span> <span class="at">-XGET</span> <span class="va">${A_SIGNED_DOWNLOAD_URL}</span> <span class="at">--output</span> /data/msls_<span class="va">${BATCH_NUM}</span>.zip <span class="kw">&amp;&amp;</span><span class="dt">\</span></span>
    <span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">sudo</span> unzip <span class="at">-qq</span> /data/msls_<span class="va">${BATCH_NUM}</span>.zip <span class="at">-d</span> /data/imgs</span></code></pre></div>
    <hr />
    <h2 id="model-training">Model Training</h2>
    <p>I designed model training to be as simple as possible. On a GPU instance, the following should be adequate to begin training. All flags for <code>python3 -m msls.run_dcgan</code> are shown below. Please see the CLI <code>--help</code> to understand what each flag and value does in the example below.</p>
    <div class="sourceCode" id="cb2"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a></span>
    <span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="ex">python3</span> <span class="at">-m</span> pip install <span class="at">--upgrade</span> pip <span class="kw">&amp;&amp;</span><span class="dt">\</span></span>
    <span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">sudo</span> <span class="at">-H</span> pip3 install /path/to/msls/package/model</span>
    <span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a></span>
    <span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="co"># In short, the below does a 16 epoch run on a model with:</span></span>
    <span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
    <span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Id: `global-dcgan-128-1`</span></span>
    <span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Image data data from: `/data/imgs/train_val/`</span></span>
    <span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Saving checkpoints to: `/efs/trained_model/`</span></span>
    <span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Uploading an artifact to: `s3://dmw2151-habana-model-outputs`</span></span>
    <span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
    <span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a><span class="ex">python3</span> <span class="at">-m</span> msls.run_dcgan <span class="dt">\</span></span>
    <span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>    <span class="at">-c</span> <span class="st">&#39;{&quot;name&quot;: &quot;global-dcgan-128-1&quot;, &quot;root&quot;: &quot;/efs/trained_model/&quot;, &quot;log_frequency&quot;: 50, &quot;save_frequency&quot;: 1}&#39;</span> <span class="dt">\</span></span>
    <span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>    <span class="at">-t</span> <span class="st">&#39;{&quot;nc&quot;: 3, &quot;nz&quot;: 128, &quot;ngf&quot;: 128, &quot;ndf&quot;: 32, &quot;lr&quot;: 0.0002, &quot;beta1&quot;: 0.5, &quot;beta2&quot;: 0.999, &quot;batch_size&quot;: 256, &quot;img_size&quot;: 128, &quot;weight_decay&quot;: 0.05}&#39;</span><span class="dt">\</span></span>
    <span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>    <span class="at">--s_epoch</span> 0 <span class="dt">\</span></span>
    <span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>    <span class="at">--n_epoch</span> 16 <span class="dt">\</span></span>
    <span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>    <span class="at">--dataroot</span> /data/imgs/train_val/ <span class="dt">\</span></span>
    <span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>    <span class="at">--logging</span> True <span class="dt">\</span></span>
    <span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>    <span class="at">--profile</span> True  <span class="dt">\</span></span>
    <span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>    <span class="at">--s3_bucket</span> <span class="st">&#39;dmw2151-habana-model-outputs&#39;</span></span></code></pre></div>
    <p>In the case above, the <code>msls</code> package will fall back to training on the GPU because no HPU is available. However, when a call to <code>load_habana_module()</code> succeeds, the model will prefer to train on the HPU. For example, rather than running <code>python3 -m msls.run_dcgan</code> directly on the host, I can spin up a Habana PyTorch container, mount the proper volumes, and then run the same training script as above.</p>
    <div class="sourceCode" id="cb3"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a></span>
    <span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="co"># From the host, launch a PyTorch Container w. the proper Volumes...</span></span>
    <span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="ex">docker</span> run <span class="at">-ti</span> <span class="at">--runtime</span><span class="op">=</span>habana <span class="dt">\</span></span>
    <span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">-e</span> HABANA_VISIBLE_DEVICES=all <span class="dt">\</span></span>
    <span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">-e</span> OMPI_MCA_btl_vader_single_copy_mechanism=none <span class="dt">\</span></span>
    <span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">--cap-add</span><span class="op">=</span>sys_nice <span class="dt">\</span></span>
    <span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">--net</span><span class="op">=</span>host <span class="dt">\</span></span>
    <span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">-v</span> /data:/data <span class="dt">\</span></span>
    <span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>    <span class="at">-v</span> /efs:/efs <span class="dt">\</span></span>
    <span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>    <span class="at">-v</span> /root/msls-pytorch-dcgan:/root/msls-pytorch-dcgan/ <span class="dt">\</span></span>
    <span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>    <span class="at">--ipc</span><span class="op">=</span>host <span class="dt">\</span></span>
    <span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>    vault.habana.ai/gaudi-docker/1.2.0/ubuntu18.04/habanalabs/pytorch-installer-1.10.0:1.2.0-585</span>
    <span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a></span>
    <span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Run the same command(s), but in the container</span></span>
    <span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a><span class="ex">root@xyzxyzxyz:/\#</span> python3 <span class="at">-m</span> msls.run_dcgan ....</span></code></pre></div>
    <p>Finally, If you want a truly guided experience, you can use the notebooks in <code>./model/notebooks</code> to train in a SageMaker notebook. As of writing, <code>DL1</code> is not a supported SageMaker instance type, so you’ll be restricted to GPU instances.</p>
    <h2 id="inference-new-image-generation">Inference &amp; New Image Generation</h2>
    <footer class="site-footer">
        <span class="site-footer-owner"> Maintained by <a href="https://github.com/DMW2151">DMW2151</a>.</span>
    </footer>
  </body>
</html>
